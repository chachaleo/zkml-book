<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>ZKML Book</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">ZKML Book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>ZKML uses ZKP protocols specifically tailored and optimized for machine learning operations. This book explores the ZKP techniques applied in such contexts and provides an overview of some ML concepts. The primary focus is on overviews of state-of-the-art ZKML projects, with simplified and high-level explanations of how they work.</p>
<p>This is a work in progress, and contributions are welcome on the <a href="https://github.com/chachaleo/zkml-book">Github repository</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sumcheck"><a class="header" href="#sumcheck">Sumcheck</a></h1>
<p>The prover \(P\) wants to prove to the verifier \(V\) the summation of a \(n\)-variate polynomial \(g(x_1,\ldots, x_n)\to \mathbb{F}\) on all possible binary input  \(x_i \in \{0,1\}^n\).</p>
<p>The sum results to a one dimentional constant \(H_1 \in \mathbb{F}\) and is defined by :</p>
<div align="center">
    <img src="./img/ch02-equation.png" alt="drawing" width="400">
</div>
<p>To solve this the verifier could compute the sum itself but it would consume \( 2^n \) evaluation of \(g(x_1, \ldots, x_n)\) and \( 2^n \) additions. To optimize the verifier performance, sumcheck
protocol allows  \(V\) to delegate most of the computation to \(P\), and \(P\) will do a series of computations and
communications to convince  \(V\) the correctness of the summation.</p>
<h2 id="sumcheck-iterative-protocol"><a class="header" href="#sumcheck-iterative-protocol">Sumcheck iterative protocol</a></h2>
<p>In summary, at each round \(i\)  the prover will compute the sum over \(n - i\) variable send it to the verifier, the verifier will challenge the answer of the prover and the prover will prove it with round  \(i + 1\) over  \(n - i - 1\) variables, the round  \(n\) will be the last one and will consist of a trivial sum.</p>
<p>To start the prover sends the initial sum \(H_1\). Then in the round 1, the prover computes a univariate polynomial \(g_1(X_1)\), the polynomial equals to the sum on all variables except the first one that remains unbounded.</p>
<p>Now the verifier receives the \(H_1\) value and the univariate polynomial \(g_1(X_1)\). The verifier will check that \(H_1 = g_1(0) + g_1(1)\) holds and will send a random point \(r_1\) and challenge the prover.</p>
<div align="center">
    <img src="./img/ch02-round1.png" alt="drawing" width="800">
</div>
<p>Now the prover has to send  \(H_2 = g_1(r_1)\) and prove its computation, to do that it will re-execute the sumcheck protocol on \(g_1(r_1)\) that has now \(n - 1\) variables. In round 2 the prover computes the univariate polynomial \(g_2(X_2)\), the sum of \(g\) on all variables except the first variable set to \(r_1\) and the second that remains unbounded. Note that at each round the amount of computation for the prover decreases as the number of variable decreases.</p>
<p>The verifier checks that \(H_2 = g_2(0) + g_2(1)\) holds and will send a random point \(r_2\) and challenge the prover.</p>
<div align="center">
    <img src="./img/ch02-round2.png" alt="drawing" width="800">
</div>
<p>The prover and verifier recursively apply the sumcheck protocol round by round, each round another variable of \(g\) gets bounded to a value randomly chosen by the verifier.</p>
<p>Until the last round, where the last variable of \(g\) gets bound to a variable :</p>
<div align="center">
    <img src="./img/ch02-roundn.png" alt="drawing" width="800">
</div>
<p>With all the values bounded to the randomly chosen value, the verifier can now check \(H_n = g_n(0) + g_n(1)\) trivially.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gkr-protocol"><a class="header" href="#gkr-protocol">GKR Protocol</a></h1>
<p>Protocol named ather its creators Goldwasser, Kalai, and Rothblum. GKP is an  interactive proof protocol for circuit evaluation. At its core, the main primitive used in the GKR protocol is the sum-check protocol.</p>
<p>The gates add or mul two fields elements. The prover doesn't commit to anything and the verifier need to evalutate the MLE of the input at a random point.</p>
<p>On the image below we have a small circuit with a layer of multiplication and a layer of addition. The GKR protocol first start with a claim of the output and then iteratively reduces into a claim about the layer before, until a last claim about he MLE of the input that the verifier can verify.</p>
<p>All claims are challenged randomly by the verifier, the last claim is also randomly challenged and can be verified by the verifier.</p>
<div align="center">
    <img src="./img/ch03-GKR.png" alt="drawing" width="800">
</div>
<p>We can define the following class of functions from the GKR protocol description :</p>
<div align="center">
    <img src="./img/ch03-eq.png" alt="drawing" width="300">
</div>
<p>Where :</p>
<ul>
<li>\(f_1(g, x, y)\) : Is the representation of the gates in the circuit. It is a sparse array and can be stored as a bookkeeping table (that only stores non-zero values).</li>
<li>\(f_2(x)\) and \(f_3(y)\) : Represent the inputs of the gates of the previous layers feeding into the current layer. They are multi-linear extention of arrays,</li>
</ul>
<p>Now to be able to apply the Sumcheck protocol, the equation is rewritten as :</p>
<div align="center">
    <img src="./img/ch03-facto.png" alt="drawing" width="600">
</div>
<p>Which can be solved using two successive product Sumcheck.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="normalization-in-neural-networks"><a class="header" href="#normalization-in-neural-networks">Normalization in Neural Networks</a></h1>
<p>Training Deep Neural Networks can suffer from the variation of the distribution of each layer’s inputs. This happens during the training as the parameters of the previous layers change and slows down the training by requiring lower learning rates and careful parameter initialization. This phenomenon is called <strong>Internal Covariate Shift (ICS)</strong>. Addressing this problem has been the initial motivation for normalizing layer inputs.</p>
<p>Multiple normalization solutions have been developped to reduce ICS and speading the training. But normalization has also shown beneficial effects on the gradient flow through the network, by reducing the dependence of gradients on the scale of the parameters or of their initial values. Allowing higher learning rates without the risk of divergence.</p>
<p>On the Diagram, we represented the training of a Neural Network, more specifically a Feed Forward Neural Network with one hidden layer. The training is done on a big training data set, called the Batch, here we have a batch containing <em>n</em> data items.</p>
<p><img src="./img/ch04-basic.png" alt="image" /></p>
<h2 id="batch-normalization"><a class="header" href="#batch-normalization">Batch Normalization</a></h2>
<p>A first solution Batch normalization, intruduced is this <a href="https://arxiv.org/pdf/1502.03167">paper</a>, is to standardizes each summed input across the training data using normalization.</p>
<p>It has shown to avoid the gradients to explode or vanish even with higher learning rates. By normalizing activations throughout the network, it prevents small changes
to the parameters from amplifying into larger and suboptimal changes in activations in gradients.</p>
<p><img src="./img/ch04-batch-norm.png" alt="image" /></p>
<p>The batch normalization is done independentely in each neuron.</p>
<p>\[
ā_i = \frac{a_i-\mu_i}{\sigma_i} g_i
\]</p>
<p>Where:</p>
<ul>
<li>\(\mu\) and \(\sigma\) are the mean and standard deviation of \(a_i\), computed across the batch items in a layer.</li>
<li>\(g_i\) is a learnable scaling parameter.</li>
</ul>
<h2 id="layer-normalization-layernorm"><a class="header" href="#layer-normalization-layernorm">Layer Normalization (LayerNorm)</a></h2>
<p>Another solution was then introduce in this <a href="https://arxiv.org/pdf/1607.06450">paper</a> with similar intentions : <em>LayerNorm</em>. Layer normalization normalizes the activations across the hidden units within a single layer for each data point independently, while batch normalization normalizes the activations across a mini-batch of data for each hidden unit within a layer.</p>
<p>Therefore the normalization is done at the same place in the network but is done independently for each batch items.</p>
<p><img src="./img/ch04-layer-norm.png" alt="image" /></p>
<p>Because it normalizes the pre-activation values,LayerNorm introduces a <strong>re-centering and re-scaling invariance property</strong>. The former enables the model to be insensitive to shift noises on both inputs and weights, and the latter keeps the output representations intact when both inputs and weights are randomly scaled.</p>
<p>\[
ā_i = \frac{a_i - \mu}{\sqrt{\frac{1}{n} \sum_{i=1}^n (a_i - \mu)^2}} g_i, \quad \text{where} \quad \mu = \frac{1}{n} \sum_{i=1}^n a_i
\]</p>
<p>Where:</p>
<ul>
<li>\(\mu\) and \(\sigma\) are the mean and standard deviation of \(a_i\), computed across the neurons in a layer.</li>
<li>\(g_i\) is a learnable scaling parameter.</li>
</ul>
<h2 id="root-mean-square-layer-normalization-rmsnorm"><a class="header" href="#root-mean-square-layer-normalization-rmsnorm">Root Mean Square Layer Normalization (RMSNorm)</a></h2>
<p>Finally <em>RMSNorm</em> was introduced in this <a href="https://arxiv.org/pdf/1910.07467">paper</a> and used in LLaMa2, it shows similar performance that <em>LayerNorm</em> with less computation overhead. <em>RMSNorm</em> was created from the hypothesis that the <strong>re-scaling invariance</strong> is the reason for the success of <em>LayerNorm</em>, rather than re-centering invariance. RMSNorm only focuses on re-scaling invariance and regularizes the summed inputs simply according to the root mean square (RMS). Which makes RMSNorm computationally cheaper than LayerNorm.</p>
<p><img src="./img/ch04-RMS.png" alt="image" /></p>
<p><em>RMSNorm</em> works in the same fashion as <em>LayerNorm</em>, the normalization happens for each item of the batch with the norm over all the neurons of the layer. The only difference is the computation of the norm; only the RMS is computed.</p>
<p>The formula for <em>RMSNorm</em> is:</p>
<p>\[
ā_i = \frac{a_i}{\sqrt{\frac{1}{n} \sum_{i=1}^n a_i^2}} g_i
\]</p>
<div style="break-before: page; page-break-before: always;"></div>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
